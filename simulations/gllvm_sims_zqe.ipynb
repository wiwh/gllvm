{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d89381b",
   "metadata": {},
   "source": [
    "# GLLVM Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b613e710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: ELBO=-350.64\n",
      "Epoch 2: ELBO=-340.26\n",
      "Epoch 3: ELBO=-330.61\n",
      "Epoch 4: ELBO=-323.37\n",
      "Epoch 5: ELBO=-312.27\n",
      "Epoch 6: ELBO=-304.79\n",
      "Epoch 7: ELBO=-297.22\n",
      "Epoch 8: ELBO=-289.47\n",
      "Epoch 9: ELBO=-285.26\n",
      "Epoch 10: ELBO=-280.60\n",
      "Epoch 11: ELBO=-276.68\n",
      "Epoch 12: ELBO=-275.71\n",
      "Epoch 13: ELBO=-273.43\n",
      "Epoch 14: ELBO=-272.28\n",
      "Epoch 15: ELBO=-271.75\n",
      "Epoch 16: ELBO=-269.73\n",
      "Epoch 17: ELBO=-270.53\n",
      "Epoch 18: ELBO=-270.81\n",
      "Epoch 19: ELBO=-270.25\n",
      "Epoch 20: ELBO=-270.38\n",
      "Epoch 21: ELBO=-268.44\n",
      "Epoch 22: ELBO=-268.81\n",
      "Epoch 23: ELBO=-269.56\n",
      "Epoch 24: ELBO=-269.10\n",
      "Epoch 25: ELBO=-267.94\n",
      "Epoch 26: ELBO=-268.77\n",
      "Epoch 27: ELBO=-268.68\n",
      "Epoch 28: ELBO=-268.94\n",
      "Epoch 29: ELBO=-268.42\n",
      "Epoch 30: ELBO=-268.24\n",
      "Epoch 31: ELBO=-267.65\n",
      "Epoch 32: ELBO=-269.56\n",
      "Epoch 33: ELBO=-268.56\n",
      "Epoch 34: ELBO=-267.16\n",
      "Epoch 35: ELBO=-267.36\n",
      "Epoch 36: ELBO=-268.15\n",
      "Epoch 37: ELBO=-267.55\n",
      "Epoch 38: ELBO=-267.52\n",
      "Epoch 39: ELBO=-266.88\n",
      "Epoch 40: ELBO=-266.43\n",
      "Epoch 41: ELBO=-267.38\n",
      "Epoch 42: ELBO=-267.33\n",
      "Epoch 43: ELBO=-267.14\n",
      "Epoch 44: ELBO=-268.07\n",
      "Epoch 45: ELBO=-266.61\n",
      "Epoch 46: ELBO=-267.21\n",
      "Epoch 47: ELBO=-267.30\n",
      "Epoch 48: ELBO=-267.17\n",
      "Epoch 49: ELBO=-266.62\n",
      "Epoch 50: ELBO=-266.16\n",
      "Epoch 51: ELBO=-266.70\n",
      "Epoch 52: ELBO=-266.74\n",
      "Epoch 53: ELBO=-267.12\n",
      "Epoch 54: ELBO=-267.17\n",
      "Epoch 55: ELBO=-266.42\n",
      "Epoch 56: ELBO=-267.02\n",
      "Epoch 57: ELBO=-267.45\n",
      "Epoch 58: ELBO=-266.63\n",
      "Epoch 59: ELBO=-266.87\n",
      "Epoch 60: ELBO=-266.16\n",
      "Epoch 61: ELBO=-266.50\n",
      "Epoch 62: ELBO=-267.06\n",
      "Epoch 63: ELBO=-266.03\n",
      "Epoch 64: ELBO=-266.62\n",
      "Epoch 65: ELBO=-266.45\n",
      "Epoch 66: ELBO=-266.56\n",
      "Epoch 67: ELBO=-266.93\n",
      "Epoch 68: ELBO=-266.48\n",
      "Epoch 69: ELBO=-265.82\n",
      "Epoch 70: ELBO=-265.90\n",
      "Epoch 71: ELBO=-266.65\n",
      "Epoch 72: ELBO=-266.25\n",
      "Epoch 73: ELBO=-266.15\n",
      "Epoch 74: ELBO=-264.97\n",
      "Epoch 75: ELBO=-266.70\n",
      "Epoch 76: ELBO=-266.06\n",
      "Epoch 77: ELBO=-266.03\n",
      "Epoch 78: ELBO=-266.12\n",
      "Epoch 79: ELBO=-266.24\n",
      "Epoch 80: ELBO=-265.46\n",
      "Epoch 81: ELBO=-265.95\n",
      "Epoch 82: ELBO=-266.67\n",
      "Epoch 83: ELBO=-266.00\n",
      "Epoch 84: ELBO=-265.34\n",
      "Epoch 85: ELBO=-265.98\n",
      "Epoch 86: ELBO=-265.77\n",
      "Epoch 87: ELBO=-265.90\n",
      "Epoch 88: ELBO=-265.75\n",
      "Epoch 89: ELBO=-265.89\n",
      "Epoch 90: ELBO=-266.24\n",
      "Epoch 91: ELBO=-266.37\n",
      "Epoch 92: ELBO=-265.43\n",
      "Epoch 93: ELBO=-265.42\n",
      "Epoch 94: ELBO=-265.61\n",
      "Epoch 95: ELBO=-266.05\n",
      "Epoch 96: ELBO=-266.14\n",
      "Epoch 97: ELBO=-265.55\n",
      "Epoch 98: ELBO=-265.70\n",
      "Epoch 99: ELBO=-265.44\n",
      "Epoch 100: ELBO=-266.10\n",
      "Epoch 101: ELBO=-265.42\n",
      "Epoch 102: ELBO=-265.46\n",
      "Epoch 103: ELBO=-265.43\n",
      "Epoch 104: ELBO=-266.22\n",
      "Epoch 105: ELBO=-265.41\n",
      "Epoch 106: ELBO=-266.43\n",
      "Epoch 107: ELBO=-266.43\n",
      "Epoch 108: ELBO=-265.82\n",
      "Epoch 109: ELBO=-264.67\n",
      "Epoch 110: ELBO=-265.48\n",
      "Epoch 111: ELBO=-265.83\n",
      "Epoch 112: ELBO=-267.01\n",
      "Epoch 113: ELBO=-266.48\n",
      "Epoch 114: ELBO=-265.43\n",
      "Epoch 115: ELBO=-266.23\n",
      "Epoch 116: ELBO=-266.29\n",
      "Epoch 117: ELBO=-265.57\n",
      "Epoch 118: ELBO=-266.33\n",
      "Epoch 119: ELBO=-266.14\n",
      "Epoch 120: ELBO=-265.35\n",
      "Epoch 121: ELBO=-266.14\n",
      "Epoch 122: ELBO=-265.54\n",
      "Epoch 123: ELBO=-266.64\n",
      "Epoch 124: ELBO=-266.64\n",
      "Epoch 125: ELBO=-265.54\n",
      "Epoch 126: ELBO=-266.22\n",
      "Epoch 127: ELBO=-266.43\n",
      "Epoch 128: ELBO=-265.55\n",
      "Epoch 129: ELBO=-265.81\n",
      "Epoch 130: ELBO=-265.62\n",
      "Epoch 131: ELBO=-266.19\n",
      "Epoch 132: ELBO=-266.48\n",
      "Epoch 133: ELBO=-265.60\n",
      "Epoch 134: ELBO=-266.61\n",
      "Epoch 135: ELBO=-265.78\n",
      "Epoch 136: ELBO=-265.59\n",
      "Epoch 137: ELBO=-265.68\n",
      "Epoch 138: ELBO=-265.54\n",
      "Epoch 139: ELBO=-267.25\n",
      "Epoch 140: ELBO=-265.92\n",
      "Epoch 141: ELBO=-266.04\n",
      "Epoch 142: ELBO=-265.79\n",
      "Epoch 143: ELBO=-265.88\n",
      "Epoch 144: ELBO=-265.00\n",
      "Epoch 145: ELBO=-266.56\n",
      "Epoch 146: ELBO=-266.29\n",
      "Epoch 147: ELBO=-266.38\n",
      "Epoch 148: ELBO=-266.24\n",
      "Epoch 149: ELBO=-266.23\n",
      "Epoch 150: ELBO=-266.20\n",
      "Epoch 151: ELBO=-265.82\n",
      "Epoch 152: ELBO=-266.36\n",
      "Epoch 153: ELBO=-265.90\n",
      "Epoch 154: ELBO=-266.24\n",
      "Epoch 155: ELBO=-267.40\n",
      "Epoch 156: ELBO=-266.24\n",
      "Epoch 157: ELBO=-266.68\n",
      "Epoch 158: ELBO=-265.74\n",
      "Epoch 159: ELBO=-265.82\n",
      "Epoch 160: ELBO=-265.42\n",
      "Epoch 161: ELBO=-265.87\n",
      "Epoch 162: ELBO=-266.73\n",
      "Epoch 163: ELBO=-266.53\n",
      "Epoch 164: ELBO=-266.22\n",
      "Epoch 165: ELBO=-266.24\n",
      "Epoch 166: ELBO=-266.60\n",
      "Epoch 167: ELBO=-266.73\n",
      "Epoch 168: ELBO=-266.34\n",
      "Epoch 169: ELBO=-266.79\n",
      "Epoch 170: ELBO=-265.67\n",
      "Epoch 171: ELBO=-266.08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 93\u001b[0m\n\u001b[1;32m     90\u001b[0m z \u001b[38;5;241m=\u001b[39m mu \u001b[38;5;241m+\u001b[39m eps \u001b[38;5;241m*\u001b[39m std\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# decoder log-likelihood for ELBO (no detach)\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m logpy_z \u001b[38;5;241m=\u001b[39m \u001b[43mgllvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# KL(q||p)\u001b[39;00m\n\u001b[1;32m     96\u001b[0m kl \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m logvar \u001b[38;5;241m-\u001b[39m mu\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m logvar\u001b[38;5;241m.\u001b[39mexp(), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/GitHub/gllvm/src/gllvm/gllvm_module.py:373\u001b[0m, in \u001b[0;36mGLLVM.log_prob\u001b[0;34m(self, y, linpar, z, x)\u001b[0m\n\u001b[1;32m    371\u001b[0m idx \u001b[38;5;241m=\u001b[39m fam\u001b[38;5;241m.\u001b[39midx\n\u001b[1;32m    372\u001b[0m lp \u001b[38;5;241m=\u001b[39m linpar[:, idx]\n\u001b[0;32m--> 373\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m[idx]\n\u001b[1;32m    375\u001b[0m dist \u001b[38;5;241m=\u001b[39m fam(linpar\u001b[38;5;241m=\u001b[39mlp, scale\u001b[38;5;241m=\u001b[39msc)\n\u001b[1;32m    376\u001b[0m logp[:, idx] \u001b[38;5;241m=\u001b[39m dist\u001b[38;5;241m.\u001b[39mlog_prob(y[:, idx])\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1918\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1920\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from gllvm import GLLVM, PoissonGLM, BinomialGLM, GaussianGLM\n",
    "\n",
    "seed = 123\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1. Generate synthetic data from the ground-truth model\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "gllvm0 = GLLVM(latent_dim=1, output_dim=5)\n",
    "gllvm0.add_glm(PoissonGLM, idx=[0, 1], name=\"Poisson1\")\n",
    "gllvm0.add_glm(BinomialGLM, idx=[2], name=\"Binomial1\")\n",
    "gllvm0.add_glm(GaussianGLM, idx=[3, 4], name=\"Gaussian1\")\n",
    "\n",
    "num_samples = 10_000\n",
    "z0 = gllvm0.sample_z(num_samples)\n",
    "y0 = gllvm0.sample(z=z0)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2. Build a fresh model that will be trained with VI\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "gllvm = GLLVM(latent_dim=1, output_dim=5)\n",
    "gllvm.add_glm(PoissonGLM, idx=[0, 1], name=\"Poisson1\")\n",
    "gllvm.add_glm(BinomialGLM, idx=[2], name=\"Binomial1\")\n",
    "gllvm.add_glm(GaussianGLM, idx=[3, 4], name=\"Gaussian1\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3. Build the encoder q(z|y)\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim=5, latent_dim=1, hidden=32):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.mean = nn.Linear(hidden, latent_dim)\n",
    "        self.logvar = nn.Linear(hidden, latent_dim)\n",
    "\n",
    "    def forward(self, y):\n",
    "        h = self.net(y)\n",
    "        mu = self.mean(h)\n",
    "        logvar = self.logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "encoder = Encoder(input_dim=5, latent_dim=1)\n",
    "\n",
    "\n",
    "# --- separate gllvm parameters ---\n",
    "gllvm_scale = [gllvm.scale]   # this is learned by ELBO\n",
    "gllvm_no_scale = []\n",
    "\n",
    "for name, p in gllvm.named_parameters():\n",
    "    if name != \"scale\":\n",
    "        gllvm_no_scale.append(p)\n",
    "        \n",
    "        \n",
    "optimizer_gllvm = optim.Adam(gllvm_no_scale, lr=1e-4)\n",
    "optimizer_encoder = optim.Adam(list(encoder.parameters()) + gllvm_scale, lr=1e-4)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4. VI training loop: ZQE + ELBO Encoder\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "batch_size = 256\n",
    "num_epochs = 500\n",
    "\n",
    "dataset = y0\n",
    "n = len(dataset)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    perm = torch.randperm(n)\n",
    "    total_elbo = 0.0\n",
    "\n",
    "    for i in range(0, n, batch_size):\n",
    "        idx = perm[i:i+batch_size]\n",
    "        y = dataset[idx]\n",
    "\n",
    "        # ======================================================\n",
    "        # 1. ENCODER UPDATE (phi) using ELBO ONLY\n",
    "        # ======================================================\n",
    "        optimizer_encoder.zero_grad()\n",
    "\n",
    "        # forward encoder\n",
    "        mu, logvar = encoder(y)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "\n",
    "        # decoder log-likelihood for ELBO (no detach)\n",
    "        logpy_z = gllvm.log_prob(y, z=z).sum(dim=-1)\n",
    "\n",
    "        # KL(q||p)\n",
    "        kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)\n",
    "\n",
    "        elbo = (logpy_z - kl).mean()\n",
    "        loss_elbo = -elbo\n",
    "\n",
    "        loss_elbo.backward()\n",
    "        optimizer_encoder.step()\n",
    "\n",
    "        # ======================================================\n",
    "        # 2. DECODER UPDATE (theta) using CENTERED ZQ LOSS ONLY\n",
    "        # ======================================================\n",
    "\n",
    "        optimizer_gllvm.zero_grad()\n",
    "\n",
    "        # ---- sample z ~ q(z|y) but encoder is frozen ----\n",
    "        with torch.no_grad():\n",
    "            mu, logvar = encoder(y)\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            z = mu + eps * std  # detached latent samples from q\n",
    "\n",
    "        # ---- sample model-generated pairs (zq,yq) ----\n",
    "        with torch.no_grad():\n",
    "            zq0 = gllvm.sample_z(num_samples=len(y))   # prior\n",
    "            yq = gllvm.sample(z=zq0)                  # model sample\n",
    "\n",
    "            muq, logvarq = encoder(yq)\n",
    "            stdq = torch.exp(0.5 * logvarq)\n",
    "            epsq = torch.randn_like(stdq)\n",
    "            zq = muq + epsq * stdq                    # detached\n",
    "\n",
    "        # ---- compute the centered ZQ estimating function ----\n",
    "        logpy_zqe  = gllvm.zq_log(y,  z=z).sum(dim=-1)\n",
    "        logpy_zqe2 = gllvm.zq_log(yq, z=zq).sum(dim=-1)\n",
    "\n",
    "        # ZQ loss = -(m_q - m_q_model)\n",
    "        loss_zqe = -(logpy_zqe.mean() - logpy_zqe2.mean())\n",
    "\n",
    "        loss_zqe.backward()\n",
    "        optimizer_gllvm.step()\n",
    "\n",
    "        total_elbo += elbo.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: ELBO={total_elbo:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "007c3445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder params: ['wz', 'bias']\n",
      "Scale param: ['scale']\n"
     ]
    }
   ],
   "source": [
    "print(\"Decoder params:\", [n for n,p in gllvm.named_parameters() if n!=\"scale\"])\n",
    "print(\"Scale param:\", [n for n,p in gllvm.named_parameters() if n==\"scale\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3436497b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gllvm0.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13a5444b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.0000, 1.0000, 1.0000, 0.6235, 1.4561], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gllvm.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c949dd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1115, -0.1204,  0.3696,  0.2404,  1.1969]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gllvm0.wz * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb23447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1375, -0.1140,  0.1716,  0.3320,  1.1280]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gllvm.wz * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0a80dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True W_z:\n",
      " Parameter containing:\n",
      "tensor([[-0.7856, -0.1608, -0.7251,  0.5009, -1.0102]], requires_grad=True)\n",
      "Estimated W_z:\n",
      " Parameter containing:\n",
      "tensor([[ 0.7671,  0.1664,  0.6880, -0.4997,  1.0128]], requires_grad=True)\n",
      "True bias:\n",
      " Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Estimated bias:\n",
      " Parameter containing:\n",
      "tensor([ 0.0222,  0.0058,  0.0084,  0.0049, -0.0112], requires_grad=True)\n",
      "True scale:\n",
      " Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n",
      "Estimated scale:\n",
      " Parameter containing:\n",
      "tensor([1.0000, 1.0000, 1.0000, 0.9924, 1.0000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"True W_z:\\n\", gllvm0.wz)\n",
    "print(\"Estimated W_z:\\n\", gllvm.wz)\n",
    "\n",
    "print(\"True bias:\\n\", gllvm0.bias)\n",
    "print(\"Estimated bias:\\n\", gllvm.bias)\n",
    "\n",
    "print(\"True scale:\\n\", gllvm0.scale)\n",
    "print(\"Estimated scale:\\n\", gllvm.scale)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
