{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d89381b",
   "metadata": {},
   "source": [
    "# GLLVM Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b613e710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: ELBO=-22.61\n",
      "Epoch 2: ELBO=-21.70\n",
      "Epoch 3: ELBO=-21.24\n",
      "Epoch 4: ELBO=-20.57\n",
      "Epoch 5: ELBO=-20.18\n",
      "Epoch 6: ELBO=-19.76\n",
      "Epoch 7: ELBO=-19.30\n",
      "Epoch 8: ELBO=-18.84\n",
      "Epoch 9: ELBO=-18.49\n",
      "Epoch 10: ELBO=-18.06\n",
      "Epoch 11: ELBO=-17.75\n",
      "Epoch 12: ELBO=-17.48\n",
      "Epoch 13: ELBO=-17.18\n",
      "Epoch 14: ELBO=-16.94\n",
      "Epoch 15: ELBO=-16.57\n",
      "Epoch 16: ELBO=-16.27\n",
      "Epoch 17: ELBO=-16.07\n",
      "Epoch 18: ELBO=-15.81\n",
      "Epoch 19: ELBO=-15.66\n",
      "Epoch 20: ELBO=-15.45\n",
      "Epoch 21: ELBO=-15.31\n",
      "Epoch 22: ELBO=-15.18\n",
      "Epoch 23: ELBO=-15.04\n",
      "Epoch 24: ELBO=-14.91\n",
      "Epoch 25: ELBO=-14.84\n",
      "Epoch 26: ELBO=-14.77\n",
      "Epoch 27: ELBO=-14.72\n",
      "Epoch 28: ELBO=-14.64\n",
      "Epoch 29: ELBO=-14.64\n",
      "Epoch 30: ELBO=-14.59\n",
      "Epoch 31: ELBO=-14.54\n",
      "Epoch 32: ELBO=-14.56\n",
      "Epoch 33: ELBO=-14.55\n",
      "Epoch 34: ELBO=-14.52\n",
      "Epoch 35: ELBO=-14.54\n",
      "Epoch 36: ELBO=-14.53\n",
      "Epoch 37: ELBO=-14.52\n",
      "Epoch 38: ELBO=-14.49\n",
      "Epoch 39: ELBO=-14.48\n",
      "Epoch 40: ELBO=-14.49\n",
      "Epoch 41: ELBO=-14.48\n",
      "Epoch 42: ELBO=-14.48\n",
      "Epoch 43: ELBO=-14.46\n",
      "Epoch 44: ELBO=-14.47\n",
      "Epoch 45: ELBO=-14.44\n",
      "Epoch 46: ELBO=-14.43\n",
      "Epoch 47: ELBO=-14.43\n",
      "Epoch 48: ELBO=-14.43\n",
      "Epoch 49: ELBO=-14.41\n",
      "Epoch 50: ELBO=-14.41\n",
      "Epoch 51: ELBO=-14.40\n",
      "Epoch 52: ELBO=-14.41\n",
      "Epoch 53: ELBO=-14.40\n",
      "Epoch 54: ELBO=-14.38\n",
      "Epoch 55: ELBO=-14.38\n",
      "Epoch 56: ELBO=-14.38\n",
      "Epoch 57: ELBO=-14.37\n",
      "Epoch 58: ELBO=-14.37\n",
      "Epoch 59: ELBO=-14.34\n",
      "Epoch 60: ELBO=-14.34\n",
      "Epoch 61: ELBO=-14.33\n",
      "Epoch 62: ELBO=-14.36\n",
      "Epoch 63: ELBO=-14.34\n",
      "Epoch 64: ELBO=-14.34\n",
      "Epoch 65: ELBO=-14.33\n",
      "Epoch 66: ELBO=-14.32\n",
      "Epoch 67: ELBO=-14.31\n",
      "Epoch 68: ELBO=-14.32\n",
      "Epoch 69: ELBO=-14.29\n",
      "Epoch 70: ELBO=-14.31\n",
      "Epoch 71: ELBO=-14.28\n",
      "Epoch 72: ELBO=-14.29\n",
      "Epoch 73: ELBO=-14.29\n",
      "Epoch 74: ELBO=-14.29\n",
      "Epoch 75: ELBO=-14.28\n",
      "Epoch 76: ELBO=-14.28\n",
      "Epoch 77: ELBO=-14.26\n",
      "Epoch 78: ELBO=-14.27\n",
      "Epoch 79: ELBO=-14.27\n",
      "Epoch 80: ELBO=-14.26\n",
      "Epoch 81: ELBO=-14.25\n",
      "Epoch 82: ELBO=-14.25\n",
      "Epoch 83: ELBO=-14.25\n",
      "Epoch 84: ELBO=-14.26\n",
      "Epoch 85: ELBO=-14.22\n",
      "Epoch 86: ELBO=-14.25\n",
      "Epoch 87: ELBO=-14.24\n",
      "Epoch 88: ELBO=-14.24\n",
      "Epoch 89: ELBO=-14.21\n",
      "Epoch 90: ELBO=-14.21\n",
      "Epoch 91: ELBO=-14.21\n",
      "Epoch 92: ELBO=-14.20\n",
      "Epoch 93: ELBO=-14.20\n",
      "Epoch 94: ELBO=-14.21\n",
      "Epoch 95: ELBO=-14.21\n",
      "Epoch 96: ELBO=-14.21\n",
      "Epoch 97: ELBO=-14.22\n",
      "Epoch 98: ELBO=-14.19\n",
      "Epoch 99: ELBO=-14.20\n",
      "Epoch 100: ELBO=-14.19\n",
      "Epoch 101: ELBO=-14.19\n",
      "Epoch 102: ELBO=-14.17\n",
      "Epoch 103: ELBO=-14.17\n",
      "Epoch 104: ELBO=-14.18\n",
      "Epoch 105: ELBO=-14.18\n",
      "Epoch 106: ELBO=-14.16\n",
      "Epoch 107: ELBO=-14.18\n",
      "Epoch 108: ELBO=-14.17\n",
      "Epoch 109: ELBO=-14.17\n",
      "Epoch 110: ELBO=-14.15\n",
      "Epoch 111: ELBO=-14.16\n",
      "Epoch 112: ELBO=-14.15\n",
      "Epoch 113: ELBO=-14.15\n",
      "Epoch 114: ELBO=-14.17\n",
      "Epoch 115: ELBO=-14.14\n",
      "Epoch 116: ELBO=-14.16\n",
      "Epoch 117: ELBO=-14.16\n",
      "Epoch 118: ELBO=-14.14\n",
      "Epoch 119: ELBO=-14.14\n",
      "Epoch 120: ELBO=-14.13\n",
      "Epoch 121: ELBO=-14.12\n",
      "Epoch 122: ELBO=-14.13\n",
      "Epoch 123: ELBO=-14.13\n",
      "Epoch 124: ELBO=-14.13\n",
      "Epoch 125: ELBO=-14.12\n",
      "Epoch 126: ELBO=-14.14\n",
      "Epoch 127: ELBO=-14.12\n",
      "Epoch 128: ELBO=-14.11\n",
      "Epoch 129: ELBO=-14.10\n",
      "Epoch 130: ELBO=-14.10\n",
      "Epoch 131: ELBO=-14.11\n",
      "Epoch 132: ELBO=-14.11\n",
      "Epoch 133: ELBO=-14.09\n",
      "Epoch 134: ELBO=-14.10\n",
      "Epoch 135: ELBO=-14.10\n",
      "Epoch 136: ELBO=-14.10\n",
      "Epoch 137: ELBO=-14.09\n",
      "Epoch 138: ELBO=-14.08\n",
      "Epoch 139: ELBO=-14.09\n",
      "Epoch 140: ELBO=-14.08\n",
      "Epoch 141: ELBO=-14.06\n",
      "Epoch 142: ELBO=-14.06\n",
      "Epoch 143: ELBO=-14.08\n",
      "Epoch 144: ELBO=-14.08\n",
      "Epoch 145: ELBO=-14.07\n",
      "Epoch 146: ELBO=-14.07\n",
      "Epoch 147: ELBO=-14.08\n",
      "Epoch 148: ELBO=-14.06\n",
      "Epoch 149: ELBO=-14.05\n",
      "Epoch 150: ELBO=-14.05\n",
      "Epoch 151: ELBO=-14.07\n",
      "Epoch 152: ELBO=-14.06\n",
      "Epoch 153: ELBO=-14.06\n",
      "Epoch 154: ELBO=-14.06\n",
      "Epoch 155: ELBO=-14.07\n",
      "Epoch 156: ELBO=-14.06\n",
      "Epoch 157: ELBO=-14.06\n",
      "Epoch 158: ELBO=-14.05\n",
      "Epoch 159: ELBO=-14.04\n",
      "Epoch 160: ELBO=-14.06\n",
      "Epoch 161: ELBO=-14.05\n",
      "Epoch 162: ELBO=-14.02\n",
      "Epoch 163: ELBO=-14.05\n",
      "Epoch 164: ELBO=-14.03\n",
      "Epoch 165: ELBO=-14.03\n",
      "Epoch 166: ELBO=-14.04\n",
      "Epoch 167: ELBO=-14.03\n",
      "Epoch 168: ELBO=-14.03\n",
      "Epoch 169: ELBO=-14.02\n",
      "Epoch 170: ELBO=-14.04\n",
      "Epoch 171: ELBO=-14.01\n",
      "Epoch 172: ELBO=-14.02\n",
      "Epoch 173: ELBO=-14.02\n",
      "Epoch 174: ELBO=-14.03\n",
      "Epoch 175: ELBO=-14.02\n",
      "Epoch 176: ELBO=-14.02\n",
      "Epoch 177: ELBO=-14.01\n",
      "Epoch 178: ELBO=-14.00\n",
      "Epoch 179: ELBO=-14.00\n",
      "Epoch 180: ELBO=-14.00\n",
      "Epoch 181: ELBO=-14.00\n",
      "Epoch 182: ELBO=-14.00\n",
      "Epoch 183: ELBO=-14.00\n",
      "Epoch 184: ELBO=-14.00\n",
      "Epoch 185: ELBO=-14.01\n",
      "Epoch 186: ELBO=-14.01\n",
      "Epoch 187: ELBO=-14.00\n",
      "Epoch 188: ELBO=-13.99\n",
      "Epoch 189: ELBO=-13.99\n",
      "Epoch 190: ELBO=-13.98\n",
      "Epoch 191: ELBO=-13.98\n",
      "Epoch 192: ELBO=-13.98\n",
      "Epoch 193: ELBO=-13.99\n",
      "Epoch 194: ELBO=-13.99\n",
      "Epoch 195: ELBO=-13.98\n",
      "Epoch 196: ELBO=-13.97\n",
      "Epoch 197: ELBO=-13.99\n",
      "Epoch 198: ELBO=-13.98\n",
      "Epoch 199: ELBO=-13.98\n",
      "Epoch 200: ELBO=-13.97\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from gllvm import GLLVM, PoissonGLM, BinomialGLM, GaussianGLM\n",
    "\n",
    "seed = 123\n",
    "device = \"cuda\"\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1. Generate synthetic data from the ground-truth model\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "gllvm0 = GLLVM(latent_dim=1, output_dim=5)\n",
    "gllvm0.add_glm(PoissonGLM, idx=[0, 1], name=\"Poisson1\")\n",
    "gllvm0.add_glm(BinomialGLM, idx=[2], name=\"Binomial1\")\n",
    "gllvm0.add_glm(GaussianGLM, idx=[3, 4], name=\"Gaussian1\")\n",
    "\n",
    "num_samples = 20000\n",
    "\n",
    "with torch.no_grad():\n",
    "    gllvm0.wz.mul_(1.0)\n",
    "    z0 = gllvm0.sample_z(num_samples)\n",
    "    y0 = gllvm0.sample(z=z0)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2. Build a fresh model that will be trained with VI\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "gllvm = GLLVM(latent_dim=1, output_dim=5)\n",
    "gllvm.add_glm(PoissonGLM, idx=[0, 1], name=\"Poisson1\")\n",
    "gllvm.add_glm(BinomialGLM, idx=[2], name=\"Binomial1\")\n",
    "gllvm.add_glm(GaussianGLM, idx=[3, 4], name=\"Gaussian1\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3. Build the encoder q(z|y)\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim=5, latent_dim=1, hidden=32):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.mean = nn.Linear(hidden, latent_dim)\n",
    "        self.logvar = nn.Linear(hidden, latent_dim)\n",
    "\n",
    "    def forward(self, y):\n",
    "        h = self.net(y)\n",
    "        mu = self.mean(h)\n",
    "        logvar = self.logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "encoder = Encoder(input_dim=5, latent_dim=1)\n",
    "\n",
    "\n",
    "# --- separate gllvm parameters ---\n",
    "gllvm_scale = [gllvm.log_scale]   # this is learned by ELBO\n",
    "gllvm_no_scale = []\n",
    "\n",
    "for name, p in gllvm.named_parameters():\n",
    "    if name != \"log_scale\":\n",
    "        gllvm_no_scale.append(p)\n",
    "        \n",
    "        \n",
    "optimizer_gllvm = optim.Adam(gllvm_no_scale, lr=1e-3)\n",
    "optimizer_encoder = optim.Adam(list(encoder.parameters()) + gllvm_scale, lr=1e-3)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4. VI training loop: ZQE + ELBO Encoder\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "gllvm.to(device)\n",
    "gllvm0.to(device)\n",
    "encoder.to(device)\n",
    "y0 = y0.to(device)\n",
    "\n",
    "\n",
    "batch_size = 10000\n",
    "num_epochs = 200\n",
    "\n",
    "dataset = y0\n",
    "n = len(dataset)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    perm = torch.randperm(n)\n",
    "    total_elbo = 0.0\n",
    "\n",
    "    for i in range(0, n, batch_size):\n",
    "        idx = perm[i:i+batch_size].to(device)\n",
    "        y = dataset[idx]\n",
    "\n",
    "        # ======================================================\n",
    "        # 1. ENCODER UPDATE (phi) using ELBO ONLY\n",
    "        # ======================================================\n",
    "        optimizer_encoder.zero_grad()\n",
    "\n",
    "        # forward encoder\n",
    "        mu, logvar = encoder(y)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "\n",
    "        # decoder log-likelihood for ELBO (no detach)\n",
    "        logpy_z = gllvm.log_prob(y, z=z).sum(dim=-1)\n",
    "\n",
    "        # KL(q||p)\n",
    "        kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)\n",
    "\n",
    "        elbo = (logpy_z - kl).mean()\n",
    "        loss_elbo = -elbo\n",
    "\n",
    "        loss_elbo.backward()\n",
    "        optimizer_encoder.step()\n",
    "\n",
    "        # ======================================================\n",
    "        # 2. DECODER UPDATE (theta) using CENTERED ZQ LOSS ONLY\n",
    "        # ======================================================\n",
    "\n",
    "\n",
    "        # ---- sample z ~ q(z|y) but encoder is frozen ----\n",
    "        with torch.no_grad():\n",
    "            mu, logvar = encoder(y)\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            z = mu + eps * std  # detached latent samples from q\n",
    "\n",
    "        # ---- sample model-generated pairs (zq,yq) ----\n",
    "        with torch.no_grad():\n",
    "            zq0 = gllvm.sample_z(num_samples=len(y))   # prior\n",
    "            yq = gllvm.sample(z=zq0)                  # model sample\n",
    "\n",
    "            muq, logvarq = encoder(yq)\n",
    "            stdq = torch.exp(0.5 * logvarq)\n",
    "            epsq = torch.randn_like(stdq)\n",
    "            zq = muq + epsq * stdq                    # detached\n",
    "\n",
    "        # ---- compute the centered ZQ estimating function ----\n",
    "        logpy_zqe  = gllvm.zq_log(y,  z=z).sum(dim=-1)\n",
    "        logpy_zqe2 = gllvm.zq_log(yq, z=zq).sum(dim=-1)\n",
    "\n",
    "        # ZQ loss = -(m_q - m_q_model)\n",
    "        loss_zqe = -(logpy_zqe.mean() - logpy_zqe2.mean())\n",
    "\n",
    "        optimizer_gllvm.zero_grad()\n",
    "        loss_zqe.backward()\n",
    "        optimizer_gllvm.step()\n",
    "\n",
    "        total_elbo += elbo.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: ELBO={total_elbo:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45853b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0309, device='cuda:0') tensor(0.4953, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(torch.mean((gllvm0.wz - gllvm.wz)**2), torch.mean((gllvm0.wz + gllvm.wz)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949dd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969]], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gllvm0.wz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb23447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0882, -1.1704,  0.2477,  1.4034,  1.1194]], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gllvm.wz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a80dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True W_z:\n",
      " Parameter containing:\n",
      "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Estimated W_z:\n",
      " Parameter containing:\n",
      "tensor([[ 0.0882, -1.1704,  0.2477,  1.4034,  1.1194]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "True bias:\n",
      " Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "Estimated bias:\n",
      " Parameter containing:\n",
      "tensor([ 0.0010, -0.2908, -0.0166,  0.0100,  0.0024], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "True scale:\n",
      " tensor([1., 1., 1., 1., 1.], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "Estimated scale:\n",
      " tensor([1.0000, 1.0000, 1.0000, 1.0377, 1.2141], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"True W_z:\\n\", gllvm0.wz)\n",
    "print(\"Estimated W_z:\\n\", gllvm.wz)\n",
    "\n",
    "print(\"True bias:\\n\", gllvm0.bias)\n",
    "print(\"Estimated bias:\\n\", gllvm.bias)\n",
    "\n",
    "print(\"True scale:\\n\", gllvm0.scale)\n",
    "print(\"Estimated scale:\\n\", gllvm.scale)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
