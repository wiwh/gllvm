{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d89381b",
   "metadata": {},
   "source": [
    "# GLLVM Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b613e710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: ELBO=-86.53\n",
      "Epoch 2: ELBO=-79.47\n",
      "Epoch 3: ELBO=-75.08\n",
      "Epoch 4: ELBO=-71.40\n",
      "Epoch 5: ELBO=-68.86\n",
      "Epoch 6: ELBO=-67.74\n",
      "Epoch 7: ELBO=-67.50\n",
      "Epoch 8: ELBO=-67.27\n",
      "Epoch 9: ELBO=-67.12\n",
      "Epoch 10: ELBO=-67.25\n",
      "Epoch 11: ELBO=-67.10\n",
      "Epoch 12: ELBO=-67.08\n",
      "Epoch 13: ELBO=-66.96\n",
      "Epoch 14: ELBO=-67.02\n",
      "Epoch 15: ELBO=-66.75\n",
      "Epoch 16: ELBO=-66.65\n",
      "Epoch 17: ELBO=-66.80\n",
      "Epoch 18: ELBO=-66.71\n",
      "Epoch 19: ELBO=-66.71\n",
      "Epoch 20: ELBO=-66.80\n",
      "Epoch 21: ELBO=-66.74\n",
      "Epoch 22: ELBO=-66.60\n",
      "Epoch 23: ELBO=-66.66\n",
      "Epoch 24: ELBO=-66.55\n",
      "Epoch 25: ELBO=-66.54\n",
      "Epoch 26: ELBO=-66.50\n",
      "Epoch 27: ELBO=-66.48\n",
      "Epoch 28: ELBO=-66.40\n",
      "Epoch 29: ELBO=-66.52\n",
      "Epoch 30: ELBO=-66.45\n",
      "Epoch 31: ELBO=-66.59\n",
      "Epoch 32: ELBO=-66.32\n",
      "Epoch 33: ELBO=-66.43\n",
      "Epoch 34: ELBO=-66.38\n",
      "Epoch 35: ELBO=-66.54\n",
      "Epoch 36: ELBO=-66.39\n",
      "Epoch 37: ELBO=-66.44\n",
      "Epoch 38: ELBO=-66.34\n",
      "Epoch 39: ELBO=-66.34\n",
      "Epoch 40: ELBO=-66.33\n",
      "Epoch 41: ELBO=-66.43\n",
      "Epoch 42: ELBO=-66.26\n",
      "Epoch 43: ELBO=-66.30\n",
      "Epoch 44: ELBO=-66.32\n",
      "Epoch 45: ELBO=-66.31\n",
      "Epoch 46: ELBO=-66.34\n",
      "Epoch 47: ELBO=-66.37\n",
      "Epoch 48: ELBO=-66.25\n",
      "Epoch 49: ELBO=-66.31\n",
      "Epoch 50: ELBO=-66.30\n",
      "Epoch 51: ELBO=-66.25\n",
      "Epoch 52: ELBO=-66.30\n",
      "Epoch 53: ELBO=-66.17\n",
      "Epoch 54: ELBO=-66.17\n",
      "Epoch 55: ELBO=-66.39\n",
      "Epoch 56: ELBO=-66.26\n",
      "Epoch 57: ELBO=-66.22\n",
      "Epoch 58: ELBO=-66.25\n",
      "Epoch 59: ELBO=-66.13\n",
      "Epoch 60: ELBO=-66.17\n",
      "Epoch 61: ELBO=-66.24\n",
      "Epoch 62: ELBO=-66.23\n",
      "Epoch 63: ELBO=-66.04\n",
      "Epoch 64: ELBO=-66.10\n",
      "Epoch 65: ELBO=-66.09\n",
      "Epoch 66: ELBO=-66.20\n",
      "Epoch 67: ELBO=-66.20\n",
      "Epoch 68: ELBO=-66.17\n",
      "Epoch 69: ELBO=-66.18\n",
      "Epoch 70: ELBO=-66.16\n",
      "Epoch 71: ELBO=-66.12\n",
      "Epoch 72: ELBO=-66.10\n",
      "Epoch 73: ELBO=-66.18\n",
      "Epoch 74: ELBO=-66.19\n",
      "Epoch 75: ELBO=-66.17\n",
      "Epoch 76: ELBO=-66.24\n",
      "Epoch 77: ELBO=-66.17\n",
      "Epoch 78: ELBO=-66.24\n",
      "Epoch 79: ELBO=-66.15\n",
      "Epoch 80: ELBO=-66.11\n",
      "Epoch 81: ELBO=-66.03\n",
      "Epoch 82: ELBO=-66.00\n",
      "Epoch 83: ELBO=-66.14\n",
      "Epoch 84: ELBO=-66.04\n",
      "Epoch 85: ELBO=-66.07\n",
      "Epoch 86: ELBO=-66.14\n",
      "Epoch 87: ELBO=-66.04\n",
      "Epoch 88: ELBO=-66.15\n",
      "Epoch 89: ELBO=-66.14\n",
      "Epoch 90: ELBO=-66.18\n",
      "Epoch 91: ELBO=-66.13\n",
      "Epoch 92: ELBO=-66.11\n",
      "Epoch 93: ELBO=-66.06\n",
      "Epoch 94: ELBO=-66.05\n",
      "Epoch 95: ELBO=-65.96\n",
      "Epoch 96: ELBO=-66.09\n",
      "Epoch 97: ELBO=-66.04\n",
      "Epoch 98: ELBO=-66.08\n",
      "Epoch 99: ELBO=-65.93\n",
      "Epoch 100: ELBO=-66.05\n",
      "Epoch 101: ELBO=-66.02\n",
      "Epoch 102: ELBO=-66.00\n",
      "Epoch 103: ELBO=-66.08\n",
      "Epoch 104: ELBO=-66.07\n",
      "Epoch 105: ELBO=-65.94\n",
      "Epoch 106: ELBO=-65.85\n",
      "Epoch 107: ELBO=-66.15\n",
      "Epoch 108: ELBO=-66.02\n",
      "Epoch 109: ELBO=-66.08\n",
      "Epoch 110: ELBO=-66.11\n",
      "Epoch 111: ELBO=-66.07\n",
      "Epoch 112: ELBO=-66.02\n",
      "Epoch 113: ELBO=-66.05\n",
      "Epoch 114: ELBO=-66.07\n",
      "Epoch 115: ELBO=-65.98\n",
      "Epoch 116: ELBO=-65.99\n",
      "Epoch 117: ELBO=-66.07\n",
      "Epoch 118: ELBO=-66.13\n",
      "Epoch 119: ELBO=-66.08\n",
      "Epoch 120: ELBO=-65.93\n",
      "Epoch 121: ELBO=-66.00\n",
      "Epoch 122: ELBO=-66.12\n",
      "Epoch 123: ELBO=-66.04\n",
      "Epoch 124: ELBO=-65.99\n",
      "Epoch 125: ELBO=-65.82\n",
      "Epoch 126: ELBO=-65.97\n",
      "Epoch 127: ELBO=-65.99\n",
      "Epoch 128: ELBO=-66.03\n",
      "Epoch 129: ELBO=-65.97\n",
      "Epoch 130: ELBO=-65.98\n",
      "Epoch 131: ELBO=-66.09\n",
      "Epoch 132: ELBO=-66.00\n",
      "Epoch 133: ELBO=-65.99\n",
      "Epoch 134: ELBO=-66.05\n",
      "Epoch 135: ELBO=-66.05\n",
      "Epoch 136: ELBO=-66.06\n",
      "Epoch 137: ELBO=-66.04\n",
      "Epoch 138: ELBO=-66.15\n",
      "Epoch 139: ELBO=-66.04\n",
      "Epoch 140: ELBO=-66.11\n",
      "Epoch 141: ELBO=-66.04\n",
      "Epoch 142: ELBO=-66.10\n",
      "Epoch 143: ELBO=-66.07\n",
      "Epoch 144: ELBO=-66.04\n",
      "Epoch 145: ELBO=-66.12\n",
      "Epoch 146: ELBO=-66.00\n",
      "Epoch 147: ELBO=-66.05\n",
      "Epoch 148: ELBO=-66.14\n",
      "Epoch 149: ELBO=-66.01\n",
      "Epoch 150: ELBO=-65.98\n",
      "Epoch 151: ELBO=-66.00\n",
      "Epoch 152: ELBO=-66.05\n",
      "Epoch 153: ELBO=-66.02\n",
      "Epoch 154: ELBO=-66.01\n",
      "Epoch 155: ELBO=-66.09\n",
      "Epoch 156: ELBO=-66.06\n",
      "Epoch 157: ELBO=-66.07\n",
      "Epoch 158: ELBO=-65.94\n",
      "Epoch 159: ELBO=-66.05\n",
      "Epoch 160: ELBO=-66.03\n",
      "Epoch 161: ELBO=-66.05\n",
      "Epoch 162: ELBO=-65.91\n",
      "Epoch 163: ELBO=-66.14\n",
      "Epoch 164: ELBO=-65.92\n",
      "Epoch 165: ELBO=-65.95\n",
      "Epoch 166: ELBO=-66.12\n",
      "Epoch 167: ELBO=-65.95\n",
      "Epoch 168: ELBO=-66.10\n",
      "Epoch 169: ELBO=-66.00\n",
      "Epoch 170: ELBO=-66.00\n",
      "Epoch 171: ELBO=-66.02\n",
      "Epoch 172: ELBO=-66.00\n",
      "Epoch 173: ELBO=-65.98\n",
      "Epoch 174: ELBO=-66.11\n",
      "Epoch 175: ELBO=-66.04\n",
      "Epoch 176: ELBO=-66.03\n",
      "Epoch 177: ELBO=-66.04\n",
      "Epoch 178: ELBO=-65.99\n",
      "Epoch 179: ELBO=-66.01\n",
      "Epoch 180: ELBO=-66.07\n",
      "Epoch 181: ELBO=-66.00\n",
      "Epoch 182: ELBO=-65.90\n",
      "Epoch 183: ELBO=-66.05\n",
      "Epoch 184: ELBO=-65.99\n",
      "Epoch 185: ELBO=-66.03\n",
      "Epoch 186: ELBO=-66.00\n",
      "Epoch 187: ELBO=-66.00\n",
      "Epoch 188: ELBO=-65.99\n",
      "Epoch 189: ELBO=-66.06\n",
      "Epoch 190: ELBO=-65.94\n",
      "Epoch 191: ELBO=-66.08\n",
      "Epoch 192: ELBO=-66.13\n",
      "Epoch 193: ELBO=-66.03\n",
      "Epoch 194: ELBO=-65.93\n",
      "Epoch 195: ELBO=-66.00\n",
      "Epoch 196: ELBO=-66.08\n",
      "Epoch 197: ELBO=-66.04\n",
      "Epoch 198: ELBO=-65.99\n",
      "Epoch 199: ELBO=-66.01\n",
      "Epoch 200: ELBO=-66.06\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from gllvm import GLLVM, PoissonGLM, BinomialGLM, GaussianGLM\n",
    "\n",
    "\n",
    "seed = 123\n",
    "device = \"cuda\"\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1. Generate synthetic data from the ground-truth model\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "gllvm0 = GLLVM(latent_dim=1, output_dim=5)\n",
    "gllvm0.add_glm(PoissonGLM, idx=[0, 1], name=\"Poisson1\")\n",
    "gllvm0.add_glm(BinomialGLM, idx=[2], name=\"Binomial1\")\n",
    "gllvm0.add_glm(GaussianGLM, idx=[3, 4], name=\"Gaussian1\")\n",
    "\n",
    "num_samples = 10000\n",
    "\n",
    "with torch.no_grad():\n",
    "    gllvm0.wz.mul_(1.0)\n",
    "    z0 = gllvm0.sample_z(num_samples)\n",
    "    y0 = gllvm0.sample(z=z0)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2. Build a fresh model that will be trained with VI\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "gllvm = GLLVM(latent_dim=1, output_dim=5)\n",
    "gllvm.add_glm(PoissonGLM, idx=[0, 1], name=\"Poisson1\")\n",
    "gllvm.add_glm(BinomialGLM, idx=[2], name=\"Binomial1\")\n",
    "gllvm.add_glm(GaussianGLM, idx=[3, 4], name=\"Gaussian1\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3. Build the encoder q(z|y)\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim=5, latent_dim=1, hidden=32):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.mean = nn.Linear(hidden, latent_dim)\n",
    "        self.logvar = nn.Linear(hidden, latent_dim)\n",
    "\n",
    "    def forward(self, y):\n",
    "        h = self.net(y)\n",
    "        mu = self.mean(h)\n",
    "        logvar = self.logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "encoder = Encoder(input_dim=5, latent_dim=1)\n",
    "optimizer = optim.Adam(list(gllvm.parameters()) + list(encoder.parameters()), lr=1e-3)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4. VI training loop: Standard VAE\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "gllvm.to(device)\n",
    "gllvm0.to(device)\n",
    "encoder.to(device)\n",
    "y0 = y0.to(device)\n",
    "\n",
    "\n",
    "batch_size = 1000\n",
    "num_epochs = 200\n",
    "\n",
    "dataset = y0\n",
    "n = len(dataset)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    perm = torch.randperm(n)\n",
    "\n",
    "    total_elbo = 0.0\n",
    "    for i in range(0, n, batch_size):\n",
    "        idx = perm[i:i+batch_size].to(device)\n",
    "        y = dataset[idx]\n",
    "\n",
    "        # Encode q(z|y)\n",
    "        mu, logvar = encoder(y)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "\n",
    "        # Reparameterization\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std\n",
    "\n",
    "        # Decoder log-likelihood\n",
    "        logpy_z = gllvm.log_prob(y, z=z).sum(dim=-1)  # sum over response dims\n",
    "\n",
    "        # KL(q||p)\n",
    "        kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)\n",
    "\n",
    "        elbo = (logpy_z - kl).mean()\n",
    "        loss = -elbo\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_elbo += elbo.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: ELBO={total_elbo:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43edcd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gllvm.simulations import make_mixed, simulate\n",
    "\n",
    "# define a setting *for the article*\n",
    "g0 = make_mixed(\n",
    "    n_latent=1,\n",
    "    gaussian=2,\n",
    "    poisson=2,\n",
    "    binomial=1\n",
    ")\n",
    "\n",
    "# generate data\n",
    "y0, z0 = simulate(g0, n_samples=20000, device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18e533ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3265, device='cuda:0') tensor(0.0002, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(torch.mean((gllvm0.wz - gllvm.wz)**2), torch.mean((gllvm0.wz + gllvm.wz)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a93903dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1115, -0.1204,  0.3696,  0.2404,  1.1969]], device='cuda:0',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gllvm0.wz *-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf62e4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1333, -0.1149,  0.3499,  0.2473,  1.2034]], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gllvm.wz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a80dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True W_z:\n",
      " Parameter containing:\n",
      "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Estimated W_z:\n",
      " Parameter containing:\n",
      "tensor([[ 0.1333, -0.1149,  0.3499,  0.2473,  1.2034]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "True bias:\n",
      " Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)\n",
      "Estimated bias:\n",
      " Parameter containing:\n",
      "tensor([ 0.0024,  0.0105,  0.0041, -0.0082,  0.0113], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "True scale:\n",
      " tensor([1., 1., 1., 1., 1.], device='cuda:0', grad_fn=<ExpBackward0>)\n",
      "Estimated scale:\n",
      " tensor([1.0000, 1.0000, 1.0000, 1.0130, 0.9506], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"True W_z:\\n\", gllvm0.wz)\n",
    "print(\"Estimated W_z:\\n\", gllvm.wz)\n",
    "\n",
    "print(\"True bias:\\n\", gllvm0.bias)\n",
    "print(\"Estimated bias:\\n\", gllvm.bias)\n",
    "\n",
    "print(\"True scale:\\n\", gllvm0.scale)\n",
    "print(\"Estimated scale:\\n\", gllvm.scale)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
